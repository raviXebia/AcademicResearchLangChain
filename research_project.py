# pip install streamlit requests langchain_google_genai langsmith

import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langsmith import traceable
from xml.etree import ElementTree
import requests
import os

LANGSMITH_API_KEY = "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"

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = LANGSMITH_API_KEY
os.environ["LANGCHAIN_PROJECT"] = "research_project"

GEMINI_API_KEY = "AIzaSyDuOCi8YLKyIjkGVAoaukl21W1VGVQNtLM"
os.environ["GOOGLE_API_KEY"] = GEMINI_API_KEY

llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

@traceable(name="research_conversation")
def chat_with_ai(message):
  return llm.invoke([HumanMessage(content=message)])

# Function to query arxiv for papers based on a topic
def query_arxiv(topic):
  url = f"https://export.arxiv.org/api/query?search_query=all:{topic}&start=0&max_results=5"
  response = requests.get(url)
  return response.text

def parse_arxiv_response(xml_data):
  tree = ElementTree.fromstring(xml_data)
  entries = tree.findall("{http://www.w3.org/2005/Atom}entry")
  papers = []

  for entry in entries:
    title = entry.find("{http://www.w3.org/2005/Atom}title").text
    summary = entry.find("{http://www.w3.org/2005/Atom}summary").text
    link = entry.find('{http://www.w3.org/2005/Atom}id').text
    papers.append({
        "title": title,
        "summary": summary,
        "link": link
    })

  return papers

def summarize_with_ai(content):
  # Create a prompt for summarization
  prompt = f"Summarize the following research content in 200 words:\n {content}"
  response = chat_with_ai(prompt)
  return response.content

def generate_research_questions(summary):
  prompt = f"Based on the summary of the research paper, generate relevant research questions:\n{summary}"
  response = chat_with_ai(prompt)
  return response.content

def generate_topic_ideas(content):
  prompt = f"Generate a list of new ideas to implement based on the following research content:\n {content}"
  response = chat_with_ai(prompt)
  return response.content


def academic_research_agent(topic):
  # Get the academic content from arxiv
  arxiv_data = query_arxiv(topic)
  papers = parse_arxiv_response(arxiv_data)

  for paper in papers:
    print("Paper title:", paper["title"])
    print("Paper Link:", paper["link"])
    summary = summarize_with_ai(paper["summary"])
    print("Summary generated by AI")
    print(summary)

    research_questions = generate_research_questions(summary)
    print("Generated research questions :")
    print(research_questions)

    idea_list = generate_topic_ideas(summary)
    print("Idea list")
    print(idea_list)